{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# verify if GPU is available\n",
    "if torch.cuda.is_available(): \n",
    "    \n",
    "    device = torch.device(\"cuda\")    \n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())    \n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize variables\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# mysql credentials\n",
    "PASSWORD = os.getenv(\"PASSWORD\")\n",
    "USER = os.getenv(\"USER\")\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to db\n",
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"127.0.0.1\",\n",
    "  user=USER,\n",
    "  password=PASSWORD,\n",
    "  database=\"mpp21\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_ids = {}\n",
    "\n",
    "with open('./privacy_filter/labels.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for r in reader:\n",
    "            article_ids[r[0]] = r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST IF ONLY ABSTRACT\n",
    "# db methods\n",
    "def select_article(curs, db, aid):\n",
    "    \n",
    "    curs.execute(\"\"\"SELECT title, content \n",
    "                FROM articles \n",
    "                WHERE article_id = '\"\"\" + aid + \"\"\"' \n",
    "                \"\"\")\n",
    "                #LIMIT 200\"\"\") \n",
    "    \n",
    "    arts = {}\n",
    "    result = curs.fetchall()\n",
    "    for r in result:\n",
    "        arts[aid] = {\n",
    "            \"title\": r[0],\n",
    "            \"content\": r[1],\n",
    "            \"verdict\": article_ids[aid]\n",
    "        }\n",
    "    \n",
    "    return arts[aid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = {}\n",
    "\n",
    "for a in article_ids.keys():\n",
    "    temp = select_article(mycursor, mydb, a)\n",
    "    \n",
    "    contents[a] = {\n",
    "        \"id\": a,\n",
    "        \"label\": int(temp[\"verdict\"]),\n",
    "        \"text\": temp[\"title\"] + \" \" + temp[\"content\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(contents).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TS_1909</th>\n",
       "      <td>TS_1909</td>\n",
       "      <td>0</td>\n",
       "      <td>Erotic novels growing ebook sales If you find ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT_1508</th>\n",
       "      <td>DT_1508</td>\n",
       "      <td>0</td>\n",
       "      <td>For sale at £300m, Britain's priciest house WI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GM_1513</th>\n",
       "      <td>GM_1513</td>\n",
       "      <td>0</td>\n",
       "      <td>City home at the hub of the community;Aaron Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TS_1940</th>\n",
       "      <td>TS_1940</td>\n",
       "      <td>0</td>\n",
       "      <td>Glee's Cory Monteith found dead;Foul play unli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA_1583</th>\n",
       "      <td>USA_1583</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple: 'Founders would be appalled';Tech giant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMH_1931</th>\n",
       "      <td>SMH_1931</td>\n",
       "      <td>0</td>\n",
       "      <td>Punter wants return of 'proceeds of crime' WIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYT_1441</th>\n",
       "      <td>NYT_1441</td>\n",
       "      <td>1</td>\n",
       "      <td>WikiLeaks tells of aid to leaker in U.S. inqui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFR_1702</th>\n",
       "      <td>AFR_1702</td>\n",
       "      <td>0</td>\n",
       "      <td>'I didn't want to be a battery hen';Co-working...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT_1893</th>\n",
       "      <td>DT_1893</td>\n",
       "      <td>1</td>\n",
       "      <td>Gmail users 'can't expect privacy' GOOGLE is o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMH_1881</th>\n",
       "      <td>SMH_1881</td>\n",
       "      <td>0</td>\n",
       "      <td>One-bedder is $750 a night but star rated Who ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id label                                               text\n",
       "TS_1909    TS_1909     0  Erotic novels growing ebook sales If you find ...\n",
       "DT_1508    DT_1508     0  For sale at £300m, Britain's priciest house WI...\n",
       "GM_1513    GM_1513     0  City home at the hub of the community;Aaron Le...\n",
       "TS_1940    TS_1940     0  Glee's Cory Monteith found dead;Foul play unli...\n",
       "USA_1583  USA_1583     1  Apple: 'Founders would be appalled';Tech giant...\n",
       "SMH_1931  SMH_1931     0  Punter wants return of 'proceeds of crime' WIT...\n",
       "NYT_1441  NYT_1441     1  WikiLeaks tells of aid to leaker in U.S. inqui...\n",
       "AFR_1702  AFR_1702     0  'I didn't want to be a battery hen';Co-working...\n",
       "DT_1893    DT_1893     1  Gmail users 'can't expect privacy' GOOGLE is o...\n",
       "SMH_1881  SMH_1881     0  One-bedder is $750 a night but star rated Who ..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 571\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data): # a pandas frame\n",
    "    \n",
    "    sentences = data.text.values\n",
    "    labels = data.label.values\n",
    "    \n",
    "    input_ids = []\n",
    "\n",
    "    for sent in sentences:\n",
    "        encoded_sent = tokenizer.encode(\n",
    "                            sent,                      \n",
    "                            add_special_tokens = True, \n",
    "                            max_length = 512,\n",
    "                       )\n",
    "\n",
    "\n",
    "        input_ids.append(encoded_sent)\n",
    "\n",
    "    #print(\"Sample encoding:\")\n",
    "    #print('Original: ', sentences[0])\n",
    "    #print('Token IDs:', input_ids[0])\n",
    "\n",
    "    #print()\n",
    "    #print('Max sentence length: ', max([len(sen) for sen in input_ids]))\n",
    "    \n",
    "    \n",
    "    MAX_LEN = 512\n",
    "\n",
    "    #print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "    #print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                              value=0, truncating=\"post\", padding=\"post\")\n",
    "    #print('Done.')\n",
    "    \n",
    "    attention_masks = []\n",
    "\n",
    "    for sent in input_ids:\n",
    "\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "        attention_masks.append(att_mask)\n",
    "    \n",
    "    return input_ids, labels, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets (0.8 training, 0.2 test)\n",
    "def split_data(inputs, labels, masks, split):\n",
    "\n",
    "    train_data, test_data, train_labels, test_labels = train_test_split(inputs, labels, \n",
    "                                                                random_state=2018, test_size=split)\n",
    "    # split masks\n",
    "    train_masks, test_masks, _, _ = train_test_split(masks, labels,\n",
    "                                                 random_state=2018, test_size=split)\n",
    "    \n",
    "    return train_data, test_data, train_labels, test_labels, train_masks, test_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, labels, attention_masks = prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "train_inputs, test_inputs, train_labels, test_labels, train_masks, test_masks = split_data(input_ids, labels, attention_masks, 0.2)\n",
    "\n",
    "# split train into train and validation\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = split_data(train_inputs, train_labels, train_masks, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast labels\n",
    "import numpy as np\n",
    "\n",
    "x, y, z = [], [], []\n",
    "\n",
    "[x.append(i) for i in train_labels]\n",
    "[y.append(i) for i in validation_labels]\n",
    "[z.append(i) for i in test_labels]\n",
    "\n",
    "train_labels = np.array(x)\n",
    "validation_labels = np.array(y)\n",
    "test_labels = np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert inputs and labels into torch tensors\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "test_inputs = torch.tensor(test_inputs)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "test_masks = torch.tensor(test_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 410\n",
      "validation 46\n",
      "test 115\n"
     ]
    }
   ],
   "source": [
    "print(\"train\", len(train_inputs))\n",
    "print(\"validation\", len(validation_inputs))\n",
    "print(\"test\", len(test_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 16 # 32\n",
    "\n",
    "# DataLoader for training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# DataLoader for validation set\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# DataLoader for the test set\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# load BertForSequenceClassification (pre-trained BERT model with a single linear classif. layer)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # 12-layer BERT model, uncased vocab (TODO: uncase articles)\n",
    "    # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # number of output labels\n",
    "                        # 2: binary classification\n",
    "                        # >2: multi-class   \n",
    "    output_attentions = False, # return attention weights\n",
    "    output_hidden_states = False, # return hidden states\n",
    ")\n",
    "\n",
    "# run on GPU (uncomment if GPU available on server)\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d37652e1e327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get model's parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The BERT model has {:} different named parameters.\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# get model's parameters\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "    \n",
    "print('\\n==== First Transformer ====\\n')\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "    \n",
    "print('\\n==== Output Layer ====\\n')\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdamW' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0d5cfe198a6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# AdamW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m optimizer = AdamW(model.parameters(),\n\u001b[0m\u001b[1;32m      3\u001b[0m                   \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# args.learning_rate - default is 5e-5,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-8\u001b[0m \u001b[0;31m# args.adam_epsilon  - default is 1e-8.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AdamW' is not defined"
     ]
    }
   ],
   "source": [
    "# AdamW \n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5,\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# training epochs: recommended 2-4\n",
    "epochs = 10 #test  10 # \n",
    "\n",
    "# training steps = batches * epochs\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            # default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy of predictions\n",
    "def flat_accuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "   \n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:03:01.\n",
      "  Batch    20  of     26.    Elapsed: 0:06:07.\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epoch took: 0:07:51\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.74405\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:03:06.\n",
      "  Batch    20  of     26.    Elapsed: 0:06:11.\n",
      "\n",
      "  Average training loss: 0.38\n",
      "  Training epoch took: 0:07:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.78571\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:03:03.\n",
      "  Batch    20  of     26.    Elapsed: 0:06:09.\n",
      "\n",
      "  Average training loss: 0.24\n",
      "  Training epoch took: 0:07:54\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80655\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:03:04.\n",
      "  Batch    20  of     26.    Elapsed: 0:06:09.\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epoch took: 0:07:53\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.83036\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:03:05.\n",
      "  Batch    20  of     26.    Elapsed: 0:06:13.\n",
      "\n",
      "  Average training loss: 0.10\n",
      "  Training epoch took: 0:07:57\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80952\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:03:06.\n",
      "  Batch    20  of     26.    Elapsed: 0:06:13.\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epoch took: 0:07:57\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80952\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:03:08.\n",
      "  Batch    20  of     26.    Elapsed: 0:06:16.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epoch took: 0:08:01\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80952\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:03:07.\n",
      "  Batch    20  of     26.    Elapsed: 0:06:12.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epoch took: 0:07:56\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80952\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:03:09.\n",
      "  Batch    20  of     26.    Elapsed: 0:06:19.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epoch took: 0:08:04\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.78571\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "  Batch    10  of     26.    Elapsed: 0:03:12.\n",
      "  Batch    20  of     26.    Elapsed: 0:06:25.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epoch took: 0:08:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80952\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# store average loss after each epoch\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "models = {}\n",
    "stats = {}\n",
    "\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # full pass over the training set    \n",
    "    print()\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')    \n",
    "    t0 = time.time() # measure epoch length\n",
    "    total_loss = 0 # reset total loss for current epoch\n",
    "    \n",
    "    # place model in training mode\n",
    "    model.train()    \n",
    "\n",
    "    # for each batch\n",
    "    for step, batch in enumerate(train_dataloader):        \n",
    "        #print(\"Step: \", step)\n",
    "        # updated on progress every 40 batches\n",
    "        if step % 10 == 0 and not step == 0:\n",
    "\n",
    "            elapsed = format_time(time.time() - t0) # compute elapsed time\n",
    "            \n",
    "            # report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))        \n",
    "            \n",
    "        # unpack training batch from DataLoader\n",
    "        # copy each tensor to GPU ('to' method)\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)        \n",
    "        \n",
    "        # clear previously calculated gradients before a backward pass\n",
    "        model.zero_grad()                \n",
    "        \n",
    "        # forward pass (i.e., evaluate the model on this training batch)\n",
    "        # this returns the loss (and not the model output), because we provided the `labels`\n",
    "\n",
    "        # documentation for model function:\n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # get loss value\n",
    "        loss = outputs[0]        \n",
    "        \n",
    "        # accumulate training loss over all batches (to compute average loss at the end)\n",
    "        total_loss += loss.item()     \n",
    "        \n",
    "        # backward pass to calculate gradients\n",
    "        loss.backward()        \n",
    "        \n",
    "        # clip the norm of the gradients to 1.0 to prevent the 'exploding gradients' problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)        \n",
    "        \n",
    "        # update parameters (the optimizer dictates the update rule based on gradients, learning rate, etc.)\n",
    "        # take a step using the computed gradient\n",
    "        optimizer.step() \n",
    "        \n",
    "        # update the learning rate.\n",
    "        scheduler.step()    \n",
    "    \n",
    "    # calculate average loss over training data\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # store the loss value to plot the learning curve\n",
    "    loss_values.append(avg_train_loss)    \n",
    "    \n",
    "    print()\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    \n",
    "\n",
    "    # after each training epoch, measure performance on validation set\n",
    "    print()\n",
    "    print(\"Running Validation...\")    \n",
    "    t0 = time.time()   \n",
    "    \n",
    "    ### STORE MODEL\n",
    "    models[epoch_i] = model\n",
    "    fn = \"models/model_e\" + str(epoch_i) + \".sav\"\n",
    "    pickle.dump(model, open(fn, 'wb'))\n",
    "    \n",
    "    # place model in evaluation mode (dropout layers behave differently than during training)\n",
    "    model.eval()    \n",
    "    \n",
    "    # tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0    \n",
    "    \n",
    "    # evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # unpack inputs from DataLoader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        \n",
    "        # do not compute or store gradients to save memory and speedup validation\n",
    "        with torch.no_grad():                    \n",
    "            # forward pass, calculate logit predictions\n",
    "                # will return logits (not the loss, because we have not provided labels)\n",
    "            # token_type_ids = segment ids (differentiates between sentence 1 and 2 in 2-sentence tasks)\n",
    "            \n",
    "            \n",
    "            # documentation for model\n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # get logits (output) from model\n",
    "        # values prior to applying an activation function (e.g., softmax)\n",
    "        logits = outputs[0]    \n",
    "        \n",
    "        # move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # compute accuracy for current batch \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # accumulate accuracy\n",
    "        eval_accuracy += tmp_eval_accuracy        \n",
    "        # track batches\n",
    "        nb_eval_steps += 1    \n",
    "        # report final accuracy for current validation run\n",
    "    print(\"  Accuracy: {0:.5f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "    stats[epoch_i] = {\n",
    "        \"acc\": round(eval_accuracy/nb_eval_steps, 5),\n",
    "        \"avg-loss\": round(avg_train_loss, 5)\n",
    "    }\n",
    "    print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'acc': 0.74405, 'avg-loss': 0.57587},\n",
       " 1: {'acc': 0.78571, 'avg-loss': 0.37848},\n",
       " 2: {'acc': 0.80655, 'avg-loss': 0.24405},\n",
       " 3: {'acc': 0.83036, 'avg-loss': 0.14597},\n",
       " 4: {'acc': 0.80952, 'avg-loss': 0.09608},\n",
       " 5: {'acc': 0.80952, 'avg-loss': 0.05703},\n",
       " 6: {'acc': 0.80952, 'avg-loss': 0.04228},\n",
       " 7: {'acc': 0.80952, 'avg-loss': 0.03855},\n",
       " 8: {'acc': 0.78571, 'avg-loss': 0.03685},\n",
       " 9: {'acc': 0.80952, 'avg-loss': 0.03845}}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # save models to disk\n",
    "\n",
    "# for m in models.keys():\n",
    "#     fn = \"models/model_e\" + str(m) + \".sav\"\n",
    "#     pickle.dump(models[m], open(fn, 'wb'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats\n",
    "\n",
    "def pick_best_model(scores):\n",
    "    \n",
    "    max_acc = 0\n",
    "    m = -1\n",
    "    \n",
    "    # for all scores\n",
    "    for s in scores.keys():\n",
    "        if scores[s][\"acc\"] > max_acc:\n",
    "            max_acc = scores[s][\"acc\"]\n",
    "            m = s\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_model(m):\n",
    "    return pickle.load(open(\"models/model_e\" + str(m) + \".sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(9)#pick_best_model(stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 115 test documents...\n",
      "\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "# prediction on test set\n",
    "print('Predicting labels for {:,} test documents...'.format(len(test_inputs)))\n",
    "\n",
    "# place model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# tracking variables \n",
    "predictions, true_labels = [], []\n",
    "\n",
    "# predict \n",
    "for batch in test_dataloader:\n",
    "    # add batch to GPU (if available)\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "    # unpack inputs from DataLoader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        # forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask) \n",
    "        \n",
    "    logits = outputs[0]  \n",
    "    \n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "print('\\nDONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# for each batch\n",
    "for i in range(len(true_labels)):\n",
    "    # predictions are a 2-column ndarray (one for 0, one for 1)\n",
    "    # pick label with highest value and turn it into 1 or 0\n",
    "\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "    # calculate and store coef for current batch\n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.836\n"
     ]
    }
   ],
   "source": [
    "# combine the predictions for each batch into a single list of 0s and 1s\n",
    "\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# combine the correct labels for each batch into a single list\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_matrix(x, y):\n",
    "    return confusion_matrix(np.array(x), y).ravel()\n",
    "\n",
    "def get_recall(x, y):\n",
    "    return recall_score(x, y, average='macro')\n",
    "    \n",
    "def get_precision(x, y):\n",
    "    return precision_score(x, y, average='macro')\n",
    "\n",
    "def get_f1_score(x, y):\n",
    "    return f1_score(x, y, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TN: 62 \n",
      "TP: 43 \n",
      "FN: 0 \n",
      "FP: 10\n",
      "Recall: 0.931\n",
      "Precision: 0.906\n",
      "F1-score: 0.911\n"
     ]
    }
   ],
   "source": [
    "x_data = flat_true_labels\n",
    "y_data = flat_predictions\n",
    "\n",
    "tn, fp, fn, tp = get_conf_matrix(x_data, y_data)#confusion_matrix(np.array(flat_true_labels), flat_predictions).ravel()\n",
    "print(\n",
    "    \"\\nTN:\", tn,\n",
    "    \"\\nTP:\", tp,\n",
    "    \"\\nFN:\", fn,\n",
    "    \"\\nFP:\", fp    \n",
    ")\n",
    "\n",
    "recall = round(get_recall(x_data, y_data), 3)\n",
    "precision = round(get_precision(x_data, y_data), 3)\n",
    "f1 = round(get_f1_score(x_data, y_data), 3)\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save final mode; to disk\n",
    "\n",
    "# for m in models.keys():\n",
    "#     fn = \"model_e\" + str(m) + \".sav\"\n",
    "#     pickle.dump(models[m], open(fn, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_articles_for_prediction(curs, db, n):\n",
    "    \n",
    "    curs.execute(\"\"\"SELECT article_id, title, content \n",
    "                FROM articles \n",
    "                WHERE newspaper = '\"\"\" + n + \"\"\"' \n",
    "                AND year(DATE) != '2010'\n",
    "                AND is_privacy != 'duplicate'\n",
    "                \"\"\")\n",
    "                #LIMIT 200\"\"\") \n",
    "    \n",
    "    arts = {}\n",
    "    result = curs.fetchall()\n",
    "    for r in result:\n",
    "        arts[r[0]] = {\n",
    "            \"title\": r[1],\n",
    "            \"content\": r[2]\n",
    "        }\n",
    "    \n",
    "    return arts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get privacy label\n",
    "def is_privacy(d):\n",
    "    \n",
    "    # tokenize\n",
    "    encoded_sent = tokenizer.encode(d, add_special_tokens = True, max_length = 512)\n",
    "    \n",
    "    # pad\n",
    "    input_id = pad_sequences([encoded_sent], maxlen=512, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    #print(input_id)\n",
    "    \n",
    "    # create attention mask\n",
    "    seq_mask = [float(i>0) for i in input_id[0]]\n",
    "\n",
    "    # convert to tensors\n",
    "    prediction_input = torch.tensor(input_id)\n",
    "    prediction_mask = torch.tensor([seq_mask])\n",
    "    output = MODEL(prediction_input, token_type_ids=None, \n",
    "                      attention_mask=prediction_mask) \n",
    "        \n",
    "    logits = output[0]  \n",
    "    \n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    # store predictions and true labels\n",
    "    verdict = np.argmax(logits[0])\n",
    "\n",
    "    return int(verdict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update record in table as duplicate\n",
    "\n",
    "def update_is_privacy(curs, db, dup, aID):\n",
    "\n",
    "    # compile query\n",
    "    insertQuery = \"UPDATE articles SET is_privacy = (%s) WHERE article_id = (%s)\"\n",
    "    insertValues = (dup, aID)\n",
    "    \n",
    "    curs.execute(insertQuery, insertValues)\n",
    "    \n",
    "    db.commit() # commit query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_to_predict = select_articles_for_prediction(mycursor, mydb, \"TG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_to_predict = {}\n",
    "\n",
    "for a in articles_to_predict.keys():\n",
    "    \n",
    "    contents_to_predict[a] = {\n",
    "        \"id\": a,\n",
    "        \"text\": articles_to_predict[a][\"title\"] + \" \" + articles_to_predict[a][\"content\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12584"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contents_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 300 Left: 12284\n",
      "Predicted: 600 Left: 11984\n",
      "Predicted: 900 Left: 11684\n",
      "Predicted: 1200 Left: 11384\n",
      "Predicted: 1500 Left: 11084\n",
      "Predicted: 1800 Left: 10784\n",
      "Predicted: 2100 Left: 10484\n",
      "Predicted: 2400 Left: 10184\n",
      "Predicted: 2700 Left: 9884\n",
      "Predicted: 3000 Left: 9584\n",
      "Predicted: 3300 Left: 9284\n",
      "Predicted: 3600 Left: 8984\n",
      "Predicted: 3900 Left: 8684\n",
      "Predicted: 4200 Left: 8384\n",
      "Predicted: 4500 Left: 8084\n",
      "Predicted: 4800 Left: 7784\n",
      "Predicted: 5100 Left: 7484\n",
      "Predicted: 5400 Left: 7184\n",
      "Predicted: 5700 Left: 6884\n",
      "Predicted: 6000 Left: 6584\n",
      "Predicted: 6300 Left: 6284\n",
      "Predicted: 6600 Left: 5984\n",
      "Predicted: 6900 Left: 5684\n",
      "Predicted: 7200 Left: 5384\n",
      "Predicted: 7500 Left: 5084\n",
      "Predicted: 7800 Left: 4784\n",
      "Predicted: 8100 Left: 4484\n",
      "Predicted: 8400 Left: 4184\n",
      "Predicted: 8700 Left: 3884\n",
      "Predicted: 9000 Left: 3584\n",
      "Predicted: 9300 Left: 3284\n",
      "Predicted: 9600 Left: 2984\n",
      "Predicted: 9900 Left: 2684\n",
      "Predicted: 10200 Left: 2384\n",
      "Predicted: 10500 Left: 2084\n",
      "Predicted: 10800 Left: 1784\n",
      "Predicted: 11100 Left: 1484\n",
      "Predicted: 11400 Left: 1184\n",
      "Predicted: 11700 Left: 884\n",
      "Predicted: 12000 Left: 584\n",
      "Predicted: 12300 Left: 284\n"
     ]
    }
   ],
   "source": [
    "priv = 0\n",
    "non_priv = 0\n",
    "verdicts = {}\n",
    "ctr = 0\n",
    "\n",
    "\n",
    "for i in contents_to_predict.keys():\n",
    "    v = is_privacy(contents_to_predict[i][\"text\"])\n",
    "    verdicts[i] = v\n",
    "    \n",
    "    ctr += 1\n",
    "    if ctr % 300 == 0:\n",
    "        print(\"Predicted:\", ctr, \"Left:\", len(contents_to_predict) - ctr)\n",
    "    if v == 1:\n",
    "        priv += 1\n",
    "    elif v == 0:\n",
    "        non_priv += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privacy: 7435\n",
      "59.08\n",
      "Non-privacy: 5149\n",
      "40.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Privacy:\", priv)\n",
    "print(round(priv * 100 / len(contents_to_predict.keys()), 2))\n",
    "\n",
    "print(\"Non-privacy:\", non_priv)\n",
    "print(round(non_priv * 100 / len(contents_to_predict.keys()), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in verdicts.keys():\n",
    "    if verdicts[a] == 1:\n",
    "        #print(\"update to privacy\")\n",
    "        update_is_privacy(mycursor, mydb, \"privacy\", a)\n",
    "        \n",
    "    elif verdicts[a] == 0:\n",
    "        #print(\"update to non-privacy\")\n",
    "        update_is_privacy(mycursor, mydb, \"non-priv\", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # db methods\n",
    "# def select_if_dup(curs, db, a):\n",
    "    \n",
    "#     curs.execute(\"SELECT is_privacy FROM articles WHERE article_id = '\" + a + \"'\") \n",
    "    \n",
    "#     arts = {}\n",
    "#     result = curs.fetchall()\n",
    "#     for r in result:\n",
    "#         arts[a] = {\n",
    "#             \"is_privacy\": r[0]\n",
    "#         }\n",
    "    \n",
    "#     return arts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verdicts = {}\n",
    "# for i in ids:\n",
    "#     temp = select_if_dup(mycursor, mydb, i)\n",
    "#     verdicts[i] = temp[i][\"is_privacy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in verdicts.keys():\n",
    "#     if verdicts[i] == \"duplicate\":\n",
    "#         print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # update record in table as duplicate\n",
    "\n",
    "# def update_tone(curs, db, dup, aID):\n",
    "\n",
    "#     # compile query\n",
    "#     insertQuery = \"UPDATE articles SET is_privacy = (%s) WHERE article_id = (%s)\"\n",
    "#     insertValues = (dup, aID)\n",
    "    \n",
    "#     curs.execute(insertQuery, insertValues)\n",
    "    \n",
    "#     db.commit() # commit query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_tone(mycursor, mydb, \"duplicate\", \"SMH_2629\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2362\r\n",
      "3089\r\n",
      "4501\r\n",
      "10445\r\n",
      "10477\r\n",
      "10509\r\n",
      "10542\r\n",
      "10574\r\n",
      "10606\r\n",
      "10638\r\n",
      "10670\r\n",
      "10705\r\n",
      "10737\r\n",
      "10770\r\n",
      "10806\r\n",
      "10838\r\n",
      "10873\r\n",
      "10906\r\n",
      "10938\r\n",
      "10971\r\n",
      "11003\r\n",
      "11038\r\n"
     ]
    }
   ],
   "source": [
    "!pgrep rsession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blah\n"
     ]
    }
   ],
   "source": [
    "print(\"blah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\u001b[H\u001b[2J\u001b[mtop - 19:34:10 up 305 days, 20:18, 11 users,  load average: 14.25, 53.57, 87.21\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 704 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   3 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 504 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   1 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m  8.2 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  1.0 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 90.7 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.1 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 19799081+\u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 79221968 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m 79987840 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m 38780996 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m 31250428 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m  3598432 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m 27651996 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 11557044+\u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\u001b[7m  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3087 root      20   0 28.999g 0.021t  22908 S  1016 11.6  77:06.72 python3     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 5483 afd8      20   0 22.026g 0.020t  49096 R  94.7 10.9   2:37.43 rsession    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m32725 afd8      20   0 1007728 142952   5172 R  89.5  0.1   6814:10 nautilus    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 5739 root      20   0   41052   4180   3096 R  21.1  0.0   0:00.05 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m  186 root      20   0       0      0      0 S   5.3  0.0   0:49.29 ksoftirqd/+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3134 root      20   0  617520  45104   6768 S   5.3  0.0   1:07.05 python3     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    1 root      20   0  185672   4644   3176 S   0.0  0.0   2:28.16 systemd     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    2 root      20   0       0      0      0 S   0.0  0.0   0:08.79 kthreadd    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    4 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 kworker/0:+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    7 root       0 -20       0      0      0 I   0.0  0.0   0:00.00 mm_percpu_+ \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    8 root      20   0       0      0      0 S   0.0  0.0   3:24.81 ksoftirqd/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m    9 root      20   0       0      0      0 I   0.0  0.0 518:12.59 rcu_sched   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   10 root      20   0       0      0      0 I   0.0  0.0   0:00.00 rcu_bh      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   11 root      rt   0       0      0      0 S   0.0  0.0   0:42.46 migration/0 \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   12 root      rt   0       0      0      0 S   0.0  0.0   0:45.21 watchdog/0  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/0     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m   14 root      20   0       0      0      0 S   0.0  0.0   0:00.00 cpuhp/1     \u001b[m\u001b[m\u001b[K\u001b[H\u001b[mtop - 19:34:13 up 305 days, 20:18, 11 users,  load average: 14.55, 52.97, 86.84\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "Tasks:\u001b[m\u001b[m\u001b[1m 704 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m   3 \u001b[m\u001b[mrunning,\u001b[m\u001b[m\u001b[1m 504 \u001b[m\u001b[msleeping,\u001b[m\u001b[m\u001b[1m   0 \u001b[m\u001b[mstopped,\u001b[m\u001b[m\u001b[1m   1 \u001b[m\u001b[mzombie\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "%Cpu(s):\u001b[m\u001b[m\u001b[1m 43.5 \u001b[m\u001b[mus,\u001b[m\u001b[m\u001b[1m  6.4 \u001b[m\u001b[msy,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mni,\u001b[m\u001b[m\u001b[1m 49.9 \u001b[m\u001b[mid,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mwa,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mhi,\u001b[m\u001b[m\u001b[1m  0.1 \u001b[m\u001b[msi,\u001b[m\u001b[m\u001b[1m  0.0 \u001b[m\u001b[mst\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Mem :\u001b[m\u001b[m\u001b[1m 19799081+\u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m 81849216 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m 77360608 \u001b[m\u001b[mused,\u001b[m\u001b[m\u001b[1m 38780992 \u001b[m\u001b[mbuff/cache\u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "KiB Swap:\u001b[m\u001b[m\u001b[1m 31250428 \u001b[m\u001b[mtotal,\u001b[m\u001b[m\u001b[1m  3598432 \u001b[m\u001b[mfree,\u001b[m\u001b[m\u001b[1m 27651996 \u001b[m\u001b[mused.\u001b[m\u001b[m\u001b[1m 11819768+\u001b[m\u001b[mavail Mem \u001b[m\u001b[m\u001b[m\u001b[m\u001b[K\n",
      "\u001b[K\n",
      "\n",
      "\u001b[m 3087 root      20   0 26.280g 0.019t  22908 S  1170 10.1  77:42.06 python3     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m32725 afd8      20   0 1007728 142952   5172 R 100.3  0.1   6814:13 nautilus    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 5483 afd8      20   0 22.241g 0.020t  49096 R 100.0 11.0   2:40.45 rsession    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m18883 afd8      20   0 2247272 911324   4028 S  39.7  0.5  18668:40 nautilus    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 4677 kunhif    20   0 2127388 877344   3608 S  37.7  0.4  17516:17 nautilus    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m21875 afd8      20   0 2366532 1.163g   3788 S  34.8  0.6  49187:18 nautilus    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 5273 afd8      20   0 2267804 1.130g   3952 S  28.1  0.6  83205:42 nautilus    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 7367 afd8      20   0 2049172 903512   3488 S  26.8  0.5  19115:10 nautilus    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m23339 afd8      20   0 2148924 1.033g   3844 S  25.8  0.5  82810:02 nautilus    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m21117 afd8      20   0 2046116 904828   3412 S  18.5  0.5  18897:07 nautilus    \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 3134 root      20   0  617520  45104   6768 S   3.3  0.0   1:07.15 python3     \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 5405 afd8      20   0 29.383g 0.011t    136 S   2.0  5.7   8178:12 MATLAB      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m23513 afd8      20   0 23.986g 5.701g  61040 S   2.0  3.0   9364:58 MATLAB      \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m11155 kunhif    20   0 3135088 196084  38424 S   1.3  0.1   4404:51 MainThread  \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 5262 afd8      20   0  249204  19480   2560 S   0.7  0.0   1586:15 Xtightvnc   \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m 5546 afd8      20   0   41092   4256   3112 S   0.7  0.0   0:01.32 top         \u001b[m\u001b[m\u001b[K\n",
      "\u001b[m\u001b[1m 5739 root      20   0   41052   4180   3096 R   0.7  0.0   0:00.07 top         \u001b[m\u001b[m\u001b[K\u001b[?1l\u001b>\u001b[25;1H\n",
      "\u001b[K\n"
     ]
    }
   ],
   "source": [
    "!top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
