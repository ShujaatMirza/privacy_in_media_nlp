{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# verify if GPU is available\n",
    "if torch.cuda.is_available(): \n",
    "    \n",
    "    device = torch.device(\"cuda\")    \n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())    \n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    \n",
    "else:\n",
    "    \n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "# initialize variables\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# mysql credentials\n",
    "PASSWORD = os.getenv(\"PASSWORD\")\n",
    "USER = os.getenv(\"USER\")\n",
    "\n",
    "\n",
    "# df = pd.read_csv(\"privacy.csv\") # REPLACE with data from database (title + content)\n",
    "# print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "# df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to db\n",
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"127.0.0.1\",\n",
    "  user=USER,\n",
    "  password=PASSWORD,\n",
    "  database=\"mpp21\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DATA\n",
    "# read newspaper info \n",
    "import csv\n",
    "\n",
    "newspapers = {}\n",
    "\n",
    "with open('./newspapers-collected.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for r in reader:\n",
    "            newspapers[r[0]] = r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_ids = {}\n",
    "\n",
    "with open('./labels.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for r in reader:\n",
    "            article_ids[r[0]] = r[1]\n",
    "            \n",
    "del article_ids[\"aid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 433\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TDP_1592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NYT_1547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>AFR_1961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>USA_1111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>NZH_1826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>TDP_1379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>NYT_1307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>TDP_1129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>DT_2440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AFR_1277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          aid  label\n",
       "28   TDP_1592      0\n",
       "17   NYT_1547      0\n",
       "267  AFR_1961      1\n",
       "247  USA_1111      0\n",
       "159  NZH_1826      0\n",
       "317  TDP_1379      1\n",
       "366  NYT_1307      1\n",
       "199  TDP_1129      0\n",
       "351   DT_2440      1\n",
       "45   AFR_1277      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"labels.csv\") # REPLACE with data from database (title + content)\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST IF ONLY ABSTRACT\n",
    "# db methods\n",
    "def select_article(curs, db, aid):\n",
    "    \n",
    "    curs.execute(\"\"\"SELECT title, content \n",
    "                FROM articles \n",
    "                WHERE article_id = '\"\"\" + aid + \"\"\"' \n",
    "                \"\"\")\n",
    "                #LIMIT 200\"\"\") \n",
    "    \n",
    "    arts = {}\n",
    "    result = curs.fetchall()\n",
    "    for r in result:\n",
    "        arts[aid] = {\n",
    "            \"title\": r[0],\n",
    "            \"content\": r[1],\n",
    "            \"verdict\": article_ids[aid]\n",
    "        }\n",
    "    \n",
    "    return arts[aid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = {}\n",
    "\n",
    "for a in article_ids.keys():\n",
    "    temp = select_article(mycursor, mydb, a)\n",
    "    \n",
    "    contents[a] = {\n",
    "        \"id\": a,\n",
    "        \"label\": int(temp[\"verdict\"]),\n",
    "        \"text\": temp[\"title\"] + \" \" + temp[\"content\"]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(contents).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USA_1653</th>\n",
       "      <td>USA_1653</td>\n",
       "      <td>0</td>\n",
       "      <td>Clinton team acknowledges missteps;Campaign vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DT_1866</th>\n",
       "      <td>DT_1866</td>\n",
       "      <td>0</td>\n",
       "      <td>Whatever your new year's resolution, there's a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYT_1712</th>\n",
       "      <td>NYT_1712</td>\n",
       "      <td>1</td>\n",
       "      <td>Why surveillance doesn't faze Britain FULL TEX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFR_1702</th>\n",
       "      <td>AFR_1702</td>\n",
       "      <td>0</td>\n",
       "      <td>'I didn't want to be a battery hen';Co-working...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TS_1389</th>\n",
       "      <td>TS_1389</td>\n",
       "      <td>0</td>\n",
       "      <td>Lost your cellphone? Check the coffee shop It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA_1476</th>\n",
       "      <td>USA_1476</td>\n",
       "      <td>0</td>\n",
       "      <td>Rubio, Cruz battle to be alternative to Trump;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMH_1505</th>\n",
       "      <td>SMH_1505</td>\n",
       "      <td>0</td>\n",
       "      <td>Almost cannonball ruin, but Tate finally retur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYT_1238</th>\n",
       "      <td>NYT_1238</td>\n",
       "      <td>1</td>\n",
       "      <td>Dr. Seuss offers a take on privacy;Disruptions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYT_1495</th>\n",
       "      <td>NYT_1495</td>\n",
       "      <td>1</td>\n",
       "      <td>Close the back doors FULL TEXTIn 2006, a feder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA_1600</th>\n",
       "      <td>USA_1600</td>\n",
       "      <td>1</td>\n",
       "      <td>New rules on wellness programs will let employ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id label                                               text\n",
       "USA_1653  USA_1653     0  Clinton team acknowledges missteps;Campaign vo...\n",
       "DT_1866    DT_1866     0  Whatever your new year's resolution, there's a...\n",
       "NYT_1712  NYT_1712     1  Why surveillance doesn't faze Britain FULL TEX...\n",
       "AFR_1702  AFR_1702     0  'I didn't want to be a battery hen';Co-working...\n",
       "TS_1389    TS_1389     0  Lost your cellphone? Check the coffee shop It ...\n",
       "USA_1476  USA_1476     0  Rubio, Cruz battle to be alternative to Trump;...\n",
       "SMH_1505  SMH_1505     0  Almost cannonball ruin, but Tate finally retur...\n",
       "NYT_1238  NYT_1238     1  Dr. Seuss offers a take on privacy;Disruptions...\n",
       "NYT_1495  NYT_1495     1  Close the back doors FULL TEXTIn 2006, a feder...\n",
       "USA_1600  USA_1600     1  New rules on wellness programs will let employ..."
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df.text.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample encoding:\n",
      "Original:  Fresh twist on British elegance A $30 million renovation at The Langham will replace the chintz with plantation shutters - but many of the original Georgian features loved by guests will stay, writes Samantha Hutchinson.When the BBC spent a year filming behind the scenes at a vaunted hotel in Mayfair, viewers were introduced to some its most enduring guests, many of whom loved the hotel so much they would live in its suites for months on end.While the practice of taking up residence for months at a time may not be a tradition at many of Sydney's coterie of five-star hotels, The Langham reckons it has forged a reputation as a luxury traveller's home away from home.Even at breakfast on a morning in early June, the home-style feeling is on show in the dining room when a guest strolls to the servery in a pair of chequered cashmere pyjama pants and leather and wool slippers.\"We've always had a reputation for being a little bit English, and we've also had a reputation for having a luxury home feeling,\" says general manager Sonia Lefevre.There are at least four guests staying at the hotel for an extended period, she says, as the man in the pyjamas takes his seat back at his table and resumes reading the morning papers.It's a reputation Lefevre reckons the iconic hotel on Kent Street - formerly known as The Observatory Hotel - will build on following a $30 million renovation scheduled to begin next month.Right on timeThe hotel, which will be closed for the renovation, will reopen in December.The Georgian-inspired foyer with a double staircase will be ripped out and the conference centre, function facilities and the hotel's ground-floor bar, restaurant and tea rooms will be extended to almost twice their current size.But the most ambitious element of the refurbishment lies in the hotel's 96 rooms. Each one will be gutted and refitted with new art deco-inspired interiors by GA Design, the same architects who designed the Corinthia Hotel London and the Four Seasons in Marrakech.As you walk into the hotel with its chintz in soft yellows, greens and blues, it seems as if the upgrade is arriving right on time. In 2012, then Langham Hospitality Group chief executive Brett Butcher told reporters the group had immediate plans to renovate the hotel it bought from Orient Express group for roughly $40 million. But Lefevre says it's taken time to get to know the guests, and to find out what works and what doesn't. In that time, the budget for the renovation has also doubled, she says.The extra spend is visible upon walking into a model of what the renovations will look like. GA Designs uses a palette based on creams with white-panelled walls, accented with shocks of soft pink, royal blue and a citrus yellow in a look that is a modern take on classic British elegance. Original Georgian fittings, including aged mahogany doors and rich, panelled, walk-in wardrobes, have been retained to keep some of the character of the original hotel. In a neat twist, they also help reflect what Lefevre calls the brand's \"English roots\", which date back to London's Langham Hotel, operating since 1865. \"There were a couple of things I had to put my foot down on, and the doors were one of the first things on that list,\" she says. \"They meant too much to visitors who have been coming here for a long time, which for some of them means 20 years.\"Other warm, modern touches come via the white plantation shutters that will stand where the chintz curtains once hung. But the chintz hasn't gone with the wind - a remnant remains in the form of the room's compendium, which is bound in a soft pink and gold-leaf floral print.Business travellers and couples who enjoy staying at the hotel for a long, romantic weekend may rarely have the opportunity to look inside the heavily bound compendium. But if you're planning on spending some time at the hotel and getting comfortable, it's worth your while to browse the Langham's extensive list of services and options, from treatments in the Chuan spa to handmade gourmet hampers designed for guests' picnics on Observatory Hill.Meals for cats and dogsSure enough there's a pillow menu - which many luxury travellers might now expect - but the pet menu begs a second look. The hotel has a number of rooms in which guests can bring their pets to stay, resting on monogrammed Langham-issue cat and dog beds, no less. The hotel also caters to the gastronomic needs of furry friends, with a menu created by Galileo head chef and alumnus of the restaurant Guy Savoy in Paris, Daniel Rudolph.\"Lassie's Favourite\" has beef steak with chunky vegetables, while the \"Meow Meow\" combines grilled salmon with green beans, quail egg, tuna, potatoes and olives. \"They look like proper adult meals,\" Lefevre laughs.According to Lefevre, it's all part of the home-away-from-home service. \"Being able to have your pet stay with you is part of how we make people feel like they're in their own home when they're away.\"There were no resident dogs to be found when Life &amp; Leisure visited the hotel, but according to Lefevre that's the whole point.\"People like us because we offer that privacy and we're a bit quieter than what you can find in other parts of the city,\" she says. \"Sometimes I walk into the bar on a Friday night, and it's staggering the people I see, but they're just in for a quiet drink because they know that's what they can get here.\"The Langham 89-113 Kent Street, Sydney Noteworthy Included in the hotel sale was the largest private collection of Sidney Nolan artwork\n",
      "Token IDs: [101, 4840, 9792, 2006, 2329, 27745, 1037, 1002, 2382, 2454, 10525, 2012, 1996, 11374, 3511, 2097, 5672, 1996, 5413, 5753, 2007, 10065, 28180, 2015, 1011, 2021, 2116, 1997, 1996, 2434, 9166, 2838, 3866, 2011, 6368, 2097, 2994, 1010, 7009, 11415, 17165, 1012, 2043, 1996, 4035, 2985, 1037, 2095, 7467, 2369, 1996, 5019, 2012, 1037, 12436, 16671, 2098, 3309, 1999, 28387, 1010, 7193, 2020, 3107, 2000, 2070, 2049, 2087, 16762, 6368, 1010, 2116, 1997, 3183, 3866, 1996, 3309, 2061, 2172, 2027, 2052, 2444, 1999, 2049, 19796, 2005, 2706, 2006, 2203, 1012, 2096, 1996, 3218, 1997, 2635, 2039, 5039, 2005, 2706, 2012, 1037, 2051, 2089, 2025, 2022, 1037, 4535, 2012, 2116, 1997, 3994, 1005, 1055, 17155, 7373, 1997, 2274, 1011, 2732, 9275, 1010, 1996, 11374, 3511, 29072, 2015, 2009, 2038, 16158, 1037, 5891, 2004, 1037, 9542, 21916, 1005, 1055, 2188, 2185, 2013, 2188, 1012, 2130, 2012, 6350, 2006, 1037, 2851, 1999, 2220, 2238, 1010, 1996, 2188, 1011, 2806, 3110, 2003, 2006, 2265, 1999, 1996, 7759, 2282, 2043, 1037, 4113, 27244, 2015, 2000, 1996, 8241, 2100, 1999, 1037, 3940, 1997, 18178, 4226, 5596, 5356, 13759, 1052, 2100, 3900, 2863, 6471, 1998, 5898, 1998, 12121, 7540, 7347, 1012, 1000, 2057, 1005, 2310, 2467, 2018, 1037, 5891, 2005, 2108, 1037, 2210, 2978, 2394, 1010, 1998, 2057, 1005, 2310, 2036, 2018, 1037, 5891, 2005, 2383, 1037, 9542, 2188, 3110, 1010, 1000, 2758, 2236, 3208, 16244, 3393, 7959, 12229, 1012, 2045, 2024, 2012, 2560, 2176, 6368, 6595, 2012, 1996, 3309, 2005, 2019, 3668, 2558, 1010, 2016, 2758, 1010, 2004, 1996, 2158, 1999, 1996, 1052, 2100, 3900, 9335, 3138, 2010, 2835, 2067, 2012, 2010, 2795, 1998, 13746, 2015, 3752, 1996, 2851, 4981, 1012, 2009, 1005, 1055, 1037, 5891, 3393, 7959, 12229, 29072, 2015, 1996, 14430, 3309, 2006, 5982, 2395, 1011, 3839, 2124, 2004, 1996, 9970, 3309, 1011, 2097, 3857, 2006, 2206, 1037, 1002, 2382, 2454, 10525, 5115, 2000, 4088, 2279, 3204, 1012, 2157, 2006, 2051, 10760, 3309, 1010, 2029, 2097, 2022, 2701, 2005, 1996, 10525, 1010, 2097, 2128, 26915, 1999, 2285, 1012, 1996, 9166, 1011, 4427, 16683, 2007, 1037, 3313, 10714, 2097, 2022, 9157, 2041, 1998, 1996, 3034, 2803, 1010, 3853, 4128, 1998, 1996, 3309, 1005, 1055, 2598, 1011, 2723, 3347, 1010, 4825, 1998, 5572, 4734, 2097, 2022, 3668, 2000, 2471, 3807, 2037, 2783, 2946, 1012, 2021, 1996, 2087, 12479, 5783, 1997, 1996, 24478, 3658, 1999, 1996, 3309, 1005, 1055, 5986, 4734, 1012, 2169, 2028, 2097, 2022, 9535, 3064, 1998, 27070, 3064, 2007, 2047, 2396, 21933, 1011, 4427, 20769, 2011, 11721, 2640, 1010, 1996, 2168, 8160, 2040, 2881, 1996, 2522, 6657, 15222, 2050, 3309, 2414, 1998, 1996, 2176, 3692, 1999, 9388, 16555, 15937, 1012, 2004, 2017, 3328, 2046, 1996, 3309, 2007, 2049, 5413, 5753, 1999, 3730, 3756, 2015, 1010, 15505, 1998, 5132, 1010, 2009, 3849, 2004, 2065, 1996, 12200, 2003, 7194, 2157, 2006, 2051, 1012, 1999, 2262, 1010, 2059, 11374, 3511, 15961, 2177, 2708, 3237, 12049, 14998, 2409, 12060, 1996, 2177, 2018, 6234, 3488, 2000, 17738, 16952, 1996, 3309, 2009, 4149, 2013, 16865, 4671, 2177, 2005, 5560, 1002, 2871, 2454, 1012, 2021, 3393, 7959, 12229, 2758, 2009, 1005, 1055, 102]\n",
      "\n",
      "Max sentence length:  512\n"
     ]
    }
   ],
   "source": [
    "### TODO: get head + tail of article, or first 512 words\n",
    "\n",
    "# tokenize sentences\n",
    "\n",
    "input_ids = []\n",
    "\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'                        \n",
    "                        # This function also supports truncation and conversion\n",
    "                        # to pytorch tensors, but we need to do padding, so we\n",
    "                        # can't use these features :( .\n",
    "                        max_length = 512,#64,          # Truncate all sentences.\n",
    "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "    \n",
    "print(\"Sample encoding:\")\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "\n",
    "print()\n",
    "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all sentences to 512 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# set max sequence length\n",
    "MAX_LEN = 512#64\n",
    "\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
    "\n",
    "# pad input tokens with value 0 at the end (\"post\")\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    "                          value=0, truncating=\"post\", padding=\"post\")\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "for sent in input_ids:\n",
    "    \n",
    "    # tokenID == 0 => padding, mask = 0\n",
    "    # tokenID > 0 => real token, mask = 1\n",
    "    att_mask = [int(token_id > 0) for token_id in sent]\n",
    "    \n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0.9 training, 0.1 validation\n",
    "\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "# analogously for the masks\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in train_labels:\n",
    "    x.append(i)\n",
    "    \n",
    "for j in validation_labels:\n",
    "    y.append(j)\n",
    "    \n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert inputs and labels into torch tensors\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "#tensor = torch.from_numpy(array.astype(np.uint8))\n",
    "\n",
    "\n",
    "train_labels = torch.tensor(x)#torch.from_numpy(train_labels.astype(np.uint8)))\n",
    "validation_labels = torch.tensor(y)#torch.from_numpy(validation_labels.astype(np.uint8)))\n",
    "\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note changes above by adding torch.from_numpy(array.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# set batch size fo training; for fine-tuning BERT on a specific task, 16 or 32 is recommended\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoader for training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# DataLoader for validation set\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# load BertForSequenceClassification (pre-trained BERT model with a single linear classif. layer)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # 12-layer BERT model, uncased vocab (TODO: uncase articles)\n",
    "    # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # number of output labels\n",
    "                        # 2: binary classification\n",
    "                        # >2: multi-class   \n",
    "    output_attentions = False, # return attention weights\n",
    "    output_hidden_states = False, # return hidden states\n",
    ")\n",
    "\n",
    "# run on GPU (uncomment if GPU available on server)\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# get model's parameters\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "    \n",
    "print('\\n==== First Transformer ====\\n')\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "    \n",
    "print('\\n==== Output Layer ====\\n')\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdamW \n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5,\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# training epochs: recommended 2-4\n",
    "epochs = 4\n",
    "\n",
    "# training steps = batches * epochs\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            # default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# compute accuracy of predictions\n",
    "def flat_accuracy(preds, labels):\n",
    "    \n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "   \n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.59\n",
      "  Training epoch took: 0:07:52\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.43\n",
      "  Training epoch took: 0:07:51\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:00:15\n",
      "\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.35\n",
      "  Training epoch took: 0:08:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.80\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.30\n",
      "  Training epoch took: 0:07:55\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:00:14\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# store average loss after each epoch\n",
    "loss_values = []\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # full pass over the training set    \n",
    "    print()\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')    \n",
    "    t0 = time.time() # measure epoch length\n",
    "    total_loss = 0 # reset total loss for current epoch\n",
    "    \n",
    "    # place model in training mode\n",
    "    model.train()    \n",
    "\n",
    "    # for each batch\n",
    "    for step, batch in enumerate(train_dataloader):        \n",
    "        \n",
    "        # updated on progress every 40 batches\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "\n",
    "            elapsed = format_time(time.time() - t0) # compute elapsed time\n",
    "            \n",
    "            # report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))        \n",
    "            \n",
    "        # unpack training batch from DataLoader\n",
    "        # copy each tensor to GPU ('to' method)\n",
    "        \n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)        \n",
    "        \n",
    "        # clear previously calculated gradients before a backward pass\n",
    "        model.zero_grad()                \n",
    "        \n",
    "        # forward pass (i.e., evaluate the model on this training batch)\n",
    "        # this returns the loss (and not the model output), because we provided the `labels`\n",
    "\n",
    "        # documentation for model function:\n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # get loss value\n",
    "        loss = outputs[0]        \n",
    "        \n",
    "        # accumulate training loss over all batches (to compute average loss at the end)\n",
    "        total_loss += loss.item()     \n",
    "        \n",
    "        # backward pass to calculate gradients\n",
    "        loss.backward()        \n",
    "        \n",
    "        # clip the norm of the gradients to 1.0 to prevent the 'exploding gradients' problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)        \n",
    "        \n",
    "        # update parameters (the optimizer dictates the update rule based on gradients, learning rate, etc.)\n",
    "        # take a step using the computed gradient\n",
    "        optimizer.step() \n",
    "        \n",
    "        # update the learning rate.\n",
    "        scheduler.step()    \n",
    "    \n",
    "    # calculate average loss over training data\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "    # store the loss value to plot the learning curve\n",
    "    loss_values.append(avg_train_loss)    \n",
    "    \n",
    "    print()\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    \n",
    "\n",
    "    # after each training epoch, measure performance on validation set\n",
    "    print()\n",
    "    print(\"Running Validation...\")    \n",
    "    t0 = time.time()   \n",
    "    \n",
    "    # place model in evaluation mode (dropout layers behave differently than during training)\n",
    "    model.eval()    \n",
    "    \n",
    "    # tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0    \n",
    "    \n",
    "    # evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # unpack inputs from DataLoader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        \n",
    "        # do not compute or store gradients to save memory and speedup validation\n",
    "        with torch.no_grad():                    \n",
    "            # forward pass, calculate logit predictions\n",
    "                # will return logits (not the loss, because we have not provided labels)\n",
    "            # token_type_ids = segment ids (differentiates between sentence 1 and 2 in 2-sentence tasks)\n",
    "            \n",
    "            \n",
    "            # documentation for model\n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # get logits (output) from model\n",
    "        # values prior to applying an activation function (e.g., softmax)\n",
    "        logits = outputs[0]    \n",
    "        \n",
    "        # move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # compute accuracy for current batch \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # accumulate accuracy\n",
    "        eval_accuracy += tmp_eval_accuracy        \n",
    "        # track batches\n",
    "        nb_eval_steps += 1    \n",
    "        # report final accuracy for current validation run\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.586277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.433447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.349306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.304175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Loss\n",
       "0  0.586277\n",
       "1  0.433447\n",
       "2  0.349306\n",
       "3  0.304175"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "f = pd.DataFrame(loss_values)\n",
    "f.columns=['Loss']\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATIOOOOOOOOON\n",
    "\n",
    "\n",
    "validation_ids = {}\n",
    "\n",
    "with open('./validation.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for r in reader:\n",
    "            validation_ids[r[0]] = r[1]\n",
    "            \n",
    "del validation_ids[\"aid\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST IF ONLY ABSTRACT\n",
    "# db methods\n",
    "def select_article2(curs, db, aid):\n",
    "    \n",
    "    curs.execute(\"\"\"SELECT title, content \n",
    "                FROM articles \n",
    "                WHERE article_id = '\"\"\" + aid + \"\"\"' \n",
    "                \"\"\")\n",
    "                #LIMIT 200\"\"\") \n",
    "    \n",
    "    arts = {}\n",
    "    result = curs.fetchall()\n",
    "    for r in result:\n",
    "        arts[aid] = {\n",
    "            \"title\": r[0],\n",
    "            \"content\": r[1],\n",
    "            \"verdict\": validation_ids[aid]\n",
    "        }\n",
    "    \n",
    "    return arts[aid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_contents = {}\n",
    "\n",
    "for a in validation_ids.keys():\n",
    "    temp = select_article2(mycursor, mydb, a)\n",
    "    \n",
    "    validation_contents[a] = {\n",
    "        \"id\": a,\n",
    "        \"label\": int(temp[\"verdict\"]),\n",
    "        \"text\": temp[\"title\"] + \" \" + temp[\"content\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.DataFrame.from_dict(validation_contents).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test documents: 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of test documents: {:,}\\n'.format(validation_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "sentences = validation_df.text.values #df\n",
    "labels = validation_df.label.values\n",
    "\n",
    "# tokenize documents\n",
    "input_ids = []\n",
    "\n",
    "# encode documents (as during training)\n",
    "for sent in sentences:\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,  \n",
    "                        max_length = 512,#64,          # Truncate all sentences.\n",
    "\n",
    "                        add_special_tokens = True, \n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "\n",
    "# pad inputs\n",
    "input_ids = pad_sequences(input_ids, maxlen=512, #MAX_LEN \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "# create attention masks\n",
    "attention_masks = []\n",
    "\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "print(attention_masks[0])\n",
    "    \n",
    "# convert to tensors\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "\n",
    "z = []\n",
    "\n",
    "for i in labels:\n",
    "    z.append(i)\n",
    "\n",
    "z = np.array(z)\n",
    "\n",
    "prediction_labels = torch.tensor(z)#labels)\n",
    "\n",
    "# set batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# create the DataLoader\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 6 test documents...\n",
      "\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "# prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test documents...'.format(len(prediction_inputs)))\n",
    "\n",
    "# place model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# predict \n",
    "for batch in prediction_dataloader:\n",
    "    # add batch to GPU (if available)\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "    # unpack inputs from DataLoader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "    # don't compute/store gradients to save memory and speed up prediction\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask) \n",
    "        \n",
    "    logits = outputs[0]  \n",
    "    \n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "print('\\nDONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privacy articles samples: 3 of 6 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "print('Privacy articles samples: %d of %d (%.2f%%)' % (validation_df.label.sum(), len(validation_df.label), (validation_df.label.sum() / len(validation_df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "\n",
    "# for each batch\n",
    "for i in range(len(true_labels)):\n",
    "    # predictions are a 2-column ndarray (one for 0, one for 1)\n",
    "    # pick label with highest value and turn it into 1 or 0\n",
    "\n",
    "    pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "    # calculate and store coef for current batch\n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.707\n"
     ]
    }
   ],
   "source": [
    "# combine the predictions for each batch into a single list of 0s and 1s\n",
    "\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# combine the correct labels for each batch into a single list\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "# calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 0, 0, 0, 1, 1])]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get privacy label\n",
    "def is_privacy(d):\n",
    "    \n",
    "    # tokenize\n",
    "    encoded_sent = tokenizer.encode(d, add_special_tokens = True,)\n",
    "    \n",
    "    # pad\n",
    "    input_id = pad_sequences([encoded_sent], maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    #print(input_id)\n",
    "    \n",
    "    # create attention mask\n",
    "    seq_mask = [float(i>0) for i in input_id[0]]\n",
    "\n",
    "    # convert to tensors\n",
    "    prediction_input = torch.tensor(input_id)\n",
    "    prediction_mask = torch.tensor([seq_mask])\n",
    "    output = model(prediction_input, token_type_ids=None, \n",
    "                      attention_mask=prediction_mask) \n",
    "        \n",
    "    logits = output[0]  \n",
    "    \n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    # store predictions and true labels\n",
    "    verdict = np.argmax(logits[0])\n",
    "\n",
    "    return verdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['NYT_3713', 'AFR_2248', 'NYT_3314', 'AFR_2251', 'AFR_2256', 'NYT_4136'])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_contents.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a = \"AFR_2251\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFR_2251\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(test_a)\n",
    "print(validation_contents[test_a][\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_verdict = is_privacy(validation_contents[\"AFR_2248\"][\"text\"])\n",
    "article_verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
